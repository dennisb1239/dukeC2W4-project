{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# Linear Regression Model for Predicting House Prices"]},{"cell_type":"markdown","metadata":{},"source":["This Kaggle dataset consists of roughly 3,000 property listings (observations), each with 79 property attributes, and our target, sale price. The goal is to use EDA, data cleaning, preprocessing and linear model to predict home prices given the features of the home. I will follow these steps to a successful submission:\n","\n","1. Exploratory Data Analysis\n","1. Data Preprocessing\n","    1. Fixing Skewness and Outliers\n","    1. Encoding Categorical Data\n","    1. Imputing Missing Values\n","1. Modelling\n","1. Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:40.093664Z","iopub.status.busy":"2021-06-10T05:34:40.09323Z","iopub.status.idle":"2021-06-10T05:34:41.191591Z","shell.execute_reply":"2021-06-10T05:34:41.190579Z","shell.execute_reply.started":"2021-06-10T05:34:40.093577Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","from math import sqrt\n","from scipy.stats import skew\n","import matplotlib.pyplot as plt\n","from sklearn import linear_model\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:41.193529Z","iopub.status.busy":"2021-06-10T05:34:41.19314Z","iopub.status.idle":"2021-06-10T05:34:41.198287Z","shell.execute_reply":"2021-06-10T05:34:41.197225Z","shell.execute_reply.started":"2021-06-10T05:34:41.193497Z"},"trusted":true},"outputs":[],"source":["plt.style.use(style='fivethirtyeight')\n","plt.rcParams['figure.figsize'] = (10, 6)"]},{"cell_type":"markdown","metadata":{},"source":["# Exploratory Data Analysis"]},{"cell_type":"markdown","metadata":{},"source":["In this initial investigations on data will be performed to to develop an understanding of the data, discover patterns and spot anomalies."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:41.200386Z","iopub.status.busy":"2021-06-10T05:34:41.19997Z","iopub.status.idle":"2021-06-10T05:34:41.292942Z","shell.execute_reply":"2021-06-10T05:34:41.291766Z","shell.execute_reply.started":"2021-06-10T05:34:41.200353Z"},"trusted":true},"outputs":[],"source":["# load the datasets into dataframe\n","train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n","test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:41.444781Z","iopub.status.busy":"2021-06-10T05:34:41.444446Z","iopub.status.idle":"2021-06-10T05:34:41.489864Z","shell.execute_reply":"2021-06-10T05:34:41.488699Z","shell.execute_reply.started":"2021-06-10T05:34:41.444752Z"},"trusted":true},"outputs":[],"source":["# show the first few records of train set\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:41.96912Z","iopub.status.busy":"2021-06-10T05:34:41.968768Z","iopub.status.idle":"2021-06-10T05:34:41.975942Z","shell.execute_reply":"2021-06-10T05:34:41.975135Z","shell.execute_reply.started":"2021-06-10T05:34:41.969089Z"},"trusted":true},"outputs":[],"source":["# check the number of records and columns in both of datasets\n","print('No. of records in train dataset: ', len(train.index))\n","print('No. of columns in train dataset: ', len(train.columns))\n","print('No. of records in test dataset: ', len(test.index))\n","print('No. of columns in test dataset: ', len(test.columns))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:42.001786Z","iopub.status.busy":"2021-06-10T05:34:42.001422Z","iopub.status.idle":"2021-06-10T05:34:42.02508Z","shell.execute_reply":"2021-06-10T05:34:42.024368Z","shell.execute_reply.started":"2021-06-10T05:34:42.001756Z"},"trusted":true},"outputs":[],"source":["# check the missing values\n","print ('Total missing values in train set', sum(train.isna().sum()))\n","print ('Total missing values in test set', sum(test.isna().sum()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:42.317805Z","iopub.status.busy":"2021-06-10T05:34:42.317444Z","iopub.status.idle":"2021-06-10T05:34:42.339558Z","shell.execute_reply":"2021-06-10T05:34:42.338607Z","shell.execute_reply.started":"2021-06-10T05:34:42.317774Z"},"trusted":true},"outputs":[],"source":["# check the missing values\n","print ('Total missing values in train set', sum(train.isna().sum()))\n","print ('Total missing values in test set', sum(test.isna().sum()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:42.915767Z","iopub.status.busy":"2021-06-10T05:34:42.9154Z","iopub.status.idle":"2021-06-10T05:34:42.931967Z","shell.execute_reply":"2021-06-10T05:34:42.930863Z","shell.execute_reply.started":"2021-06-10T05:34:42.915733Z"},"trusted":true},"outputs":[],"source":["train['SalePrice'].describe()"]},{"cell_type":"markdown","metadata":{},"source":["The aobve line code shows that the average sale price of a house is close to 180,000 with most of the values falling within the 130,000 to 215,000 range. Next step is to show the relationship between the columns to examine the correlations between the features and the target."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:43.383393Z","iopub.status.busy":"2021-06-10T05:34:43.38305Z","iopub.status.idle":"2021-06-10T05:34:43.408324Z","shell.execute_reply":"2021-06-10T05:34:43.407156Z","shell.execute_reply.started":"2021-06-10T05:34:43.383363Z"},"trusted":true},"outputs":[],"source":["numeric_cols = train.select_dtypes(include = [np.number])\n","corr = numeric_cols.corr()\n","print ('The Most Correlated Features with SalePrice:'), print (corr['SalePrice'].sort_values(ascending = False)[:10], '\\n')\n","print ('The Most Uncorrelated Features with SalePrice:'), print (corr['SalePrice'].sort_values(ascending = False)[-5:])"]},{"cell_type":"markdown","metadata":{},"source":["The most correlated features to sale price were the overall quality score (79%), above-ground living area (71%), garage area (64%), and number-of-car garage (62%). Next step is to plot each variable individually against SalePrice in a scatter plot to check outliers as outliers can affect the regression model by pulling the estimated regression line further away from the true population regression line."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:44.042784Z","iopub.status.busy":"2021-06-10T05:34:44.0424Z","iopub.status.idle":"2021-06-10T05:34:44.270981Z","shell.execute_reply":"2021-06-10T05:34:44.269897Z","shell.execute_reply.started":"2021-06-10T05:34:44.042752Z"},"trusted":true},"outputs":[],"source":["plt.scatter(x = train['GrLivArea'], y = train['SalePrice'])\n","plt.ylabel('SalePrice')\n","plt.xlabel('GrLivArea (Above grade \"ground\" living area square feet)')"]},{"cell_type":"markdown","metadata":{},"source":["At first glance, there are increases in living area correspond to increases in price, with few outliers."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:44.673896Z","iopub.status.busy":"2021-06-10T05:34:44.673574Z","iopub.status.idle":"2021-06-10T05:34:44.867232Z","shell.execute_reply":"2021-06-10T05:34:44.866383Z","shell.execute_reply.started":"2021-06-10T05:34:44.673869Z"},"trusted":true},"outputs":[],"source":["plt.scatter(x = train['GarageArea'], y = train['SalePrice'])\n","plt.ylabel('SalePrice')\n","plt.xlabel('GarageArea')"]},{"cell_type":"markdown","metadata":{},"source":["So there are many homes with 0 for GarageArea and there are a few outliers as well!"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["In this section the data is prepared (transformed, encoded, etc) to make it suitable for a building and training machine learning model. I chose to manually remove certain extreme outliers in the dataset to produce a better fit."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:46.010078Z","iopub.status.busy":"2021-06-10T05:34:46.009641Z","iopub.status.idle":"2021-06-10T05:34:46.03193Z","shell.execute_reply":"2021-06-10T05:34:46.030947Z","shell.execute_reply.started":"2021-06-10T05:34:46.010045Z"},"trusted":true},"outputs":[],"source":["# remove GrLivArea outliers\n","train = train[train['GrLivArea'] < 4500]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:46.395526Z","iopub.status.busy":"2021-06-10T05:34:46.395124Z","iopub.status.idle":"2021-06-10T05:34:46.402288Z","shell.execute_reply":"2021-06-10T05:34:46.401239Z","shell.execute_reply.started":"2021-06-10T05:34:46.39549Z"},"trusted":true},"outputs":[],"source":["# remove GarageArea outliers\n","train = train[train['GarageArea'] < 1200]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:46.795239Z","iopub.status.busy":"2021-06-10T05:34:46.794882Z","iopub.status.idle":"2021-06-10T05:34:46.814381Z","shell.execute_reply":"2021-06-10T05:34:46.813079Z","shell.execute_reply.started":"2021-06-10T05:34:46.795209Z"},"trusted":true},"outputs":[],"source":["# drop columns with percentage of missing values > 80%\n","train_percentage = train.isnull().sum() / train.shape[0]\n","print (train_percentage[train_percentage > 0.80])\n","train = train.drop(train_percentage[train_percentage > 0.80].index, axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:47.530073Z","iopub.status.busy":"2021-06-10T05:34:47.529726Z","iopub.status.idle":"2021-06-10T05:34:47.548524Z","shell.execute_reply":"2021-06-10T05:34:47.547155Z","shell.execute_reply.started":"2021-06-10T05:34:47.530043Z"},"trusted":true},"outputs":[],"source":["# do the same with test data\n","test_percentage = test.isnull().sum() / test.shape[0]\n","print (test_percentage[test_percentage > 0.80])\n","test = test.drop(test_percentage[test_percentage > 0.80].index, axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:51.839334Z","iopub.status.busy":"2021-06-10T05:34:51.838967Z","iopub.status.idle":"2021-06-10T05:34:51.900402Z","shell.execute_reply":"2021-06-10T05:34:51.899476Z","shell.execute_reply.started":"2021-06-10T05:34:51.839287Z"},"trusted":true},"outputs":[],"source":["# encode categorical variables\n","le = preprocessing.LabelEncoder()\n","for name in train.columns:\n","    if train[name].dtypes == 'O':\n","        train[name] = train[name].astype(str)\n","        le.fit(train[name])\n","        train[name] = le.transform(train[name])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:52.443511Z","iopub.status.busy":"2021-06-10T05:34:52.443154Z","iopub.status.idle":"2021-06-10T05:34:52.501373Z","shell.execute_reply":"2021-06-10T05:34:52.500621Z","shell.execute_reply.started":"2021-06-10T05:34:52.443482Z"},"trusted":true},"outputs":[],"source":["# do the same for testset\n","for name in test.columns:\n","    if test[name].dtypes == 'O':\n","        test[name] = test[name].astype(str)\n","        le.fit(test[name])\n","        test[name] = le.transform(test[name])"]},{"cell_type":"markdown","metadata":{},"source":["There are many ways to handle NaN values, whether to fill with the mean or median, however strings cannot be averaged or median-ed. One way to fill missing values is to impute these missing values according to their probability of occuring in the dataset to avoid single-valued imputation that impacts the quality of inference and prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:56.386556Z","iopub.status.busy":"2021-06-10T05:34:56.386043Z","iopub.status.idle":"2021-06-10T05:34:57.032804Z","shell.execute_reply":"2021-06-10T05:34:57.031773Z","shell.execute_reply.started":"2021-06-10T05:34:56.386525Z"},"trusted":true},"outputs":[],"source":["# fill missing values based on probability of occurrence\n","for column in train.columns:\n","    null_vals = train.isnull().values\n","    a, b = np.unique(train.values[~null_vals], return_counts = 1)\n","    train.loc[train[column].isna(), column] = np.random.choice(a, train[column].isnull().sum(), p = b / b.sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:57.231756Z","iopub.status.busy":"2021-06-10T05:34:57.231304Z","iopub.status.idle":"2021-06-10T05:34:57.284655Z","shell.execute_reply":"2021-06-10T05:34:57.283812Z","shell.execute_reply.started":"2021-06-10T05:34:57.231726Z"},"trusted":true},"outputs":[],"source":["# apply log transformation to reduce skewness over .75 by taking log(feature + 1)\n","skewed_train = train.apply(lambda x: skew(x.dropna()))\n","skewed_train = skewed_train[skewed_train > .75]\n","train[skewed_train.index] = np.log1p(train[skewed_train.index])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:57.779523Z","iopub.status.busy":"2021-06-10T05:34:57.779029Z","iopub.status.idle":"2021-06-10T05:34:57.831712Z","shell.execute_reply":"2021-06-10T05:34:57.830832Z","shell.execute_reply.started":"2021-06-10T05:34:57.779491Z"},"trusted":true},"outputs":[],"source":["# deal with the skewness in the test data\n","skewed_test = test.apply(lambda x: skew(x.dropna()))\n","skewed_test = skewed_test[skewed_test > .75]\n","test[skewed_test.index] = np.log1p(test[skewed_test.index])"]},{"cell_type":"markdown","metadata":{},"source":["# Modelling"]},{"cell_type":"markdown","metadata":{},"source":["I will perform a simple linear regression on the dataset to predict house prices. In order to train out the regression model, we need to first split up the data into an X list that contains the features to train on, and a y list with the target variable, in this case, the Price column."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:34:59.47327Z","iopub.status.busy":"2021-06-10T05:34:59.471082Z","iopub.status.idle":"2021-06-10T05:34:59.481414Z","shell.execute_reply":"2021-06-10T05:34:59.48053Z","shell.execute_reply.started":"2021-06-10T05:34:59.473221Z"},"trusted":true},"outputs":[],"source":["X = train.drop(['SalePrice', 'Id'], axis = 1)\n","y = train['SalePrice']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"]},{"cell_type":"markdown","metadata":{},"source":["Split the data into training and testing set using scikit-learn train_test_split function. We are using 80% of the data for training and 20% for testing, train_test_split() returns four objects:\n","\n","- **X_train**: the subset of our features used for training\n","- **X_test**: the subset which will be our ‘hold-out’ set – what we’ll use to test the model\n","- **y_train**: the target variable SalePrice which corresponds to X_train\n","- **y_test**: the target variable SalePrice which corresponds to X_test\n","\n","Now we will import the linear regression class, create an object of that class, which is the linear regression model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:35:00.031726Z","iopub.status.busy":"2021-06-10T05:35:00.03122Z","iopub.status.idle":"2021-06-10T05:35:00.035204Z","shell.execute_reply":"2021-06-10T05:35:00.034455Z","shell.execute_reply.started":"2021-06-10T05:35:00.031694Z"},"trusted":true},"outputs":[],"source":["lr = linear_model.LinearRegression()"]},{"cell_type":"markdown","metadata":{},"source":["Then using the fit method to \"fit\" the model to the dataset. What this does is nothing but make the regressor \"study\" the data and \"learn\" from it."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:35:00.869095Z","iopub.status.busy":"2021-06-10T05:35:00.868573Z","iopub.status.idle":"2021-06-10T05:35:00.903471Z","shell.execute_reply":"2021-06-10T05:35:00.902259Z","shell.execute_reply.started":"2021-06-10T05:35:00.869061Z"},"trusted":true},"outputs":[],"source":["model = lr.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["R-squared is the measure of how close the data are to the fitted regression line, in other words it measures the strength of the relationship between the model and the SalePrice on a convenient 0 – 100% scale."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:35:02.612768Z","iopub.status.busy":"2021-06-10T05:35:02.612432Z","iopub.status.idle":"2021-06-10T05:35:02.622971Z","shell.execute_reply":"2021-06-10T05:35:02.621882Z","shell.execute_reply.started":"2021-06-10T05:35:02.61274Z"},"trusted":true},"outputs":[],"source":["# make predictions based on model\n","predictions = model.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["There are three primary metrics used to evaluate linear models. These are:\n","* Mean absolute error (MAE)\n","* Mean squared error (MSE)\n","* Root mean squared error (RMSE)\n","\n","**MAE**: The easiest to understand. Represents average error.<br>\n","**MSE**: Similar to MAE but noise is exaggerated and larger errors are \"punished\". It is harder to interpret than MAE as it's not in base units, however, it is generally more popular.<br>\n","**RMSE**: Most popular metric, similar to MSE, however, the result is square rooted to make it more interpretable as it's in base units. It is recommended that RMSE be used as the primary metric to interpret your model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:35:04.355863Z","iopub.status.busy":"2021-06-10T05:35:04.355491Z","iopub.status.idle":"2021-06-10T05:35:04.363965Z","shell.execute_reply":"2021-06-10T05:35:04.36247Z","shell.execute_reply.started":"2021-06-10T05:35:04.355835Z"},"trusted":true},"outputs":[],"source":["print ('MAE is:', mean_absolute_error(y_test, predictions))\n","print ('MSE is:', mean_squared_error(y_test, predictions))\n","print ('RMSE is:', sqrt(mean_squared_error(y_test, predictions)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-10T05:35:05.996163Z","iopub.status.busy":"2021-06-10T05:35:05.995819Z","iopub.status.idle":"2021-06-10T05:35:06.176656Z","shell.execute_reply":"2021-06-10T05:35:06.175454Z","shell.execute_reply.started":"2021-06-10T05:35:05.996134Z"},"trusted":true},"outputs":[],"source":["# alpha helps to show overlapping data\n","plt.scatter(predictions, y_test, alpha = 0.7, color = 'b')\n","plt.xlabel('Predicted Price')\n","plt.ylabel('Actual Price')\n","plt.title('Linear Regression Model')"]},{"cell_type":"markdown","metadata":{},"source":["# Export Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-03T14:21:08.240204Z","iopub.status.busy":"2021-06-03T14:21:08.239824Z","iopub.status.idle":"2021-06-03T14:21:08.24666Z","shell.execute_reply":"2021-06-03T14:21:08.245583Z","shell.execute_reply.started":"2021-06-03T14:21:08.240163Z"},"trusted":true},"outputs":[],"source":["import joblib"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["joblib.dump(model, 'model.joblib')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
